#summary One-sentence summary of this page.

= Introduction =

This tutorial describes how to use the [http://www-nlp.stanford.edu/software/lex-parser.shtml StanfordParser] component of !DkPro. The parser can either be used stand-alone or as an UIMA annotator

= Stand-alone =

A demo of applying the stanford parser by itself can be found here:

   {{{
package demo;

import java.util.ArrayList;
import java.util.Collection;
import java.util.List;
import java.util.Set;
import java.io.StringReader;

import edu.stanford.nlp.objectbank.TokenizerFactory;
import edu.stanford.nlp.process.CoreLabelTokenFactory;
import edu.stanford.nlp.process.DocumentPreprocessor;
import edu.stanford.nlp.process.PTBTokenizer;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.ling.Label;
import edu.stanford.nlp.ling.TaggedWord;
import edu.stanford.nlp.trees.*;
import edu.stanford.nlp.parser.lexparser.LexicalizedParser;

class ParserDemo {

	
	public static void main(String[] args) {

		LexicalizedParser lp = new LexicalizedParser(
				"grammar/englishPCFG.ser.gz");

		demoAPI(lp);

	}
	

	public static void setOptions(LexicalizedParser lp) {
		//lp.setOptionFlags("-maxLength", "80", "-retainTmpSubcategories");
	}

	public static void demoAPI(LexicalizedParser lp) {

		// This option shows loading and using an explicit tokenizer

		String[] sentences = { "We would like to sentence the sentence.",
				"This is shit: ï¿½", "It doesn't stop." };

		for (String sent : sentences) {

			try {

				TokenizerFactory<CoreLabel> tokenizerFactory = PTBTokenizer
						.factory(new CoreLabelTokenFactory(), "untokenizable=noneKeep");

				List<CoreLabel> rawWords2 = tokenizerFactory.getTokenizer(
						new StringReader(sent)).tokenize();

				// applying the parser
				Tree parse = lp.apply(rawWords2);

				// the governor, the dependant and the relation name
				TreeGraphNode gov, dep;
				String rel;

				// forming the grammatical relations
				TreebankLanguagePack tlp = new PennTreebankLanguagePack();
				GrammaticalStructureFactory gsf = tlp
						.grammaticalStructureFactory();
				GrammaticalStructure gs = gsf.newGrammaticalStructure(parse);
				Collection<TypedDependency> tdl = gs
						.typedDependenciesCollapsed();

				// do the tagging
				ArrayList<TaggedWord> tags = parse.taggedYield();

				System.out.println("Sentence: \"" + sent + "\"\n");

				System.out.println("Tagging: ");
				TreePrint posPrinter = new TreePrint("wordsAndTags", tlp);
				posPrinter.printTree(parse);

				for (TypedDependency d : tdl) {

					gov = d.gov();
					dep = d.dep();
					rel = d.reln().toString();
					// value() - just the word (without the number)
					// index() - just the number

					System.out.println(gov.value().toLowerCase() + "#"
							+ tags.get(gov.index() - 1).tag() + "\t"
							+ dep.value().toLowerCase() + "#"
							+ tags.get(dep.index() - 1).tag() + "#" + rel);

				} // for all dependencies

			} catch (Exception e) {

				System.out.printf("Caught exception: " + e.getMessage());

			} // catch

		} // for all sentences

	}// demoAPI()

	private ParserDemo() {
	} // static methods only

} // class
   }}}

= Pre-requisites =

Either, create a new Maven project or incorporate the following to your existing Maven project.

You'll need the following dependency:

  * de.tudarmstadt.ukp.dkpro.core.stanford.stanfordparser

= Create your experiment =

An example pipeline may look like this:

= Output =